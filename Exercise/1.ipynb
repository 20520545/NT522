{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thuật toán Isolation Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10088\\1313017388.py:9: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df= pd.read_csv(\"UNSW-NB15_1.csv\")\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng các mẫu dữ liệu bất thường:  7000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    " \n",
    "# Đọc dữ liệu từ file csv vào dataframe\n",
    "df= pd.read_csv(\"/content/drive/MyDrive/Exe1_dataset/UNSW-NB15_1.csv\")\n",
    "\n",
    "'''Tien xu ly du lieu'''\n",
    "#Thay thế các giá trị NaN trong các cột numerial bằng mean của côt đó\n",
    "num_cols= df.select_dtypes(include=np.number).columns\n",
    "for col in num_cols:\n",
    "    df[col]= df[col].fillna(df[col].mean())\n",
    "\n",
    "# Chuyển đổi các giá trị categorical thành dạng số\n",
    "cat_cols= df.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    df[col]= pd.Categorical(df[col])\n",
    "    df[col]= df[col].cat.codes\n",
    "\n",
    "\n",
    "# Chuẩn hóa MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler= MinMaxScaler()\n",
    "df[df.columns]= scaler.fit_transform(df[df.columns])\n",
    "\n",
    "# Chia tap du lieu thanh 2 tap train:test= 8:2\n",
    "train,test= train_test_split(df,test_size=0.2, random_state=42)\n",
    "\n",
    "''' Ap dung thuat toan '''\n",
    "# Sử dụng thuật toán Isolation Forest để phát hiện các outlier trong tập dữ liệu\n",
    "\n",
    "clf= IsolationForest(random_state=42, contamination=0.01)\n",
    "clf.fit(df)\n",
    "\n",
    "# Gán nhãn cho từng mẫu dữ liệu trong tập dữ liệu\n",
    "labels = clf.predict(df)\n",
    "\n",
    "'''Dua ra ket qua'''\n",
    "# In ra số lượng các mẫu dữ liệu bất thường được phát hiện\n",
    "\n",
    "print(\"Số lượng các mẫu dữ liệu bất thường: \", len(df[labels==-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thuật toán OC-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10088\\2807395227.py:5: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df= pd.read_csv(\"UNSW-NB15_1.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ tập dataset UNSW-NB15_1.csv bằng pandas\n",
    "# df= pd.read_csv(\"/content/drive/MyDrive/Exe1_dataset/UNSW-NB15_1.csv\")\n",
    "df= pd.read_csv(\"UNSW-NB15_1.csv\")\n",
    "\n",
    "'''Tien xu ly du lieu'''\n",
    "#Thay thế các giá trị NaN trong các cột numerial bằng mean của côt đó\n",
    "num_cols= df.select_dtypes(include=np.number).columns\n",
    "for col in num_cols:\n",
    "    df[col]= df[col].fillna(df[col].mean())\n",
    "\n",
    "# Chuyển đổi các giá trị categorical thành dạng số\n",
    "cat_cols= df.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    df[col]= pd.Categorical(df[col])\n",
    "    df[col]= df[col].cat.codes\n",
    "\n",
    "# Chuẩn hóa MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()\n",
    "df[df.columns]= scaler.fit_transform(df[df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu thành tập huấn luyên và tập kiểm tra\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test= train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sử dụng thuật toán OC-SVM để phát hiện dữ liệu bất thường\n",
    "from sklearn.svm import OneClassSVM\n",
    "model= OneClassSVM(gamma='auto', nu=0.1, ).fit(X_train)\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "# Đếm số lượng mẫu bất thường\n",
    "n_outliers= len(y_pred[y_pred==-1])\n",
    "print('Số lượng mẫu bất thường: ', n_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSL-KDD\n",
    "## Thuật toán Isolation Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng các mẫu dữ liệu bất thường trên tập train: 1260\n",
      "Số lượng các mẫu dữ liệu bất thường trên tập test:  226\n",
      "Số lượng các mẫu dữ liệu bất thường trên cả 2 tập:  1486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# Đọc dữ liệu từ file csv vào dataframe\n",
    "df_train = pd. read_csv(\"/content/drive/MyDrive/Exe1_dataset/KDDTrain+.txt\")\n",
    "df_test = pd.read_csv (\"/content/drive/MyDrive/Exe1_dataset/KDDTest+.txt\")\n",
    "'''Tien xu ly du lieu '''\n",
    "# Thay thế giá trị NaN trong các cột numerical bằng mean của cột đó\n",
    "num_cols = df_train.select_dtypes (include=np. number).columns\n",
    "for col in num_cols:\n",
    "  df_train [col] = df_train[col].fillna(df_train [col].mean())\n",
    "\n",
    "num_cols = df_test.select_dtypes (include=np. number).columns\n",
    "for col in num_cols:\n",
    "  df_test[col] = df_test[col].fillna(df_test[col].mean())\n",
    "# Chuyển đổi các giá trị categorical thành dạng số\n",
    "cat_cols = df_train. select_dtypes (include='object').columns\n",
    "for col in cat_cols:\n",
    "  df_train [col]= pd. Categorical(df_train [col])\n",
    "  df_train [col]= df_train [col].cat.codes\n",
    "cat_cols = df_test.select_dtypes (include='object').columns\n",
    "\n",
    "for col in cat_cols:\n",
    "  df_test[col]= pd. Categorical(df_test[col])\n",
    "  df_test[col]= df_test[col].cat.codes\n",
    "\n",
    "# Chuẩn hóa MixMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler ()\n",
    "\n",
    "df_train[df_train.columns] = scaler.fit_transform(df_train[df_train.columns])\n",
    "df_test[df_test.columns] = scaler.fit_transform(df_test[df_test.columns])\n",
    "\n",
    "'''Ap dung thuat toan'''\n",
    "# Sử dụng thuật toán IsolationForest để phát hiện các outlier trong tập dữ liệu\n",
    "clf_train = IsolationForest(random_state=42, contamination=0.01)\n",
    "clf_train.fit(df_train)\n",
    "clf_test= IsolationForest(random_state=42, contamination=0.01)\n",
    "clf_test.fit (df_test)\n",
    "\n",
    "# Gán nhãn cho từng mẫu dữ liệu trong tập dữ liệu\n",
    "labels_train= clf_train.predict(df_train)\n",
    "labels_test= clf_test.predict(df_test)\n",
    "\n",
    "'''Dua ra ket qua'''\n",
    "# In ra số lượng mẫu dữ liệu bất thường được phát hiện\n",
    "print(\"Số lượng các mẫu dữ liệu bất thường trên tập train:\", len(df_train[labels_train== -1]))\n",
    "\n",
    "print(\"Số lượng các mẫu dữ liệu bất thường trên tập test: \", len(df_test[labels_test==-1]))\n",
    "\n",
    "total_anomalies= len(df_train[labels_train== -1]) + len(df_test[labels_test==-1])\n",
    "print(\"Số lượng các mẫu dữ liệu bất thường trên cả 2 tập: \", total_anomalies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thuật toán One-Class Support Vector Machine (OC-SVM) unsupervised learning algorithm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "#Đọc dữ liệu từ csv vào datframe\n",
    "# df_train= pd.read_csv(\"/content/drive/MyDrive/Exe1_dataset/KDDTrain+.txt\")\n",
    "# df_test= pd.read_csv(\"/content/drive/MyDrive/Exe1_dataset/KDDTest+.txt\")\n",
    "df_train= pd.read_csv(\"KDDdataset/KDDTrain+.txt\")\n",
    "df_test= pd.read_csv(\"KDDdataset/KDDTest+.txt\")\n",
    "\n",
    "'''Tien xu ly du lieu'''\n",
    "# Thay thế giá trị NaN trong các cột numerical bằng mean của cột đó\n",
    "num_cols= df_train.select_dtypes(include=np.number).columns\n",
    "for col in num_cols:\n",
    "    df_train[col]= df_train[col].fillna(df_train[col].mean())\n",
    "\n",
    "num_cols= df_test.select_dtypes(include=np.number).columns\n",
    "for col in num_cols:\n",
    "    df_train[col]= df_test[col].fillna(df_test[col].mean())\n",
    "\n",
    "# Chuyển đổi các giá trị categorical thành dạng số\n",
    "cat_cols= df_train.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    df_train[col]= pd.Categorical(df_train[col])\n",
    "    df_train[col]= df_train[col].cat.codes\n",
    "\n",
    "\n",
    "cat_cols= df_test.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    df_test[col]= pd.Categorical(df_test[col])\n",
    "    df_test[col]= df_test[col].cat.codes\n",
    "\n",
    "# Chuẩn hóa MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()\n",
    "df_train[df_train.columns]= scaler.fit_transform(df_train[df_train.columns])\n",
    "df_test[df_test.columns]= scaler.fit_transform(df_test[df_test.columns])\n",
    "\n",
    "\n",
    "'''Ap dung thuat toan'''\n",
    "# Sử dụng thuật toán OC-SVM để huấn luyện mô hình trên tập huấn luyện:\n",
    "from sklearn.svm import OneClassSVM\n",
    "model= OneClassSVM(gamma='auto').fit(df_train)\n",
    "y_pred= model.pred(df_test)\n",
    "\n",
    "'''Dua ra ket qua'''\n",
    "# In ra số lượng các mẫu dữ liệu bất thường được phát hiện\n",
    "anomaly_count= len(df_test[y_pred== -1])\n",
    "print(\"Số lượng các mẫu dữ liệu bất thường trên cả 2 tập: \", anomaly_count)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack Classification \n",
    "## Bot-IoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, accuracy_score, f1_score, recall_score\n",
    "# Đọc dữ liệu từ file csv vào dataframe\n",
    "df = pd.read_csv (\"/content/drive/MyDrive/Exe1_dataset/UNSW-NB15_1_label.csv\")\n",
    "'''Tien xu ly du lieu'''\n",
    "# Thay thế giá trị NaN trong các cột numerical bằng mean của cột đó\n",
    "num_cols = df.select_dtypes (include=np. number).columns\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "# Chuyển đổi các giá trị categorical thành dạng số\n",
    "cat_cols = df.select_dtypes (include='object').columns\n",
    "for col in cat_cols:\n",
    "    df[col] = pd. Categorical(df[col])\n",
    "    df[col] = df[col].cat.codes\n",
    "\n",
    "# Chuẩn hóa MixMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "# Gom nhóm các dạng tấn công khác nhau vào cùng một nhãn \"Attack\"\n",
    "df['state'] = df['state'].replace(['Fuzzers', 'Reconnaissance', 'Exploits', 'Analysis', 'Backdoor', 'DoS', 'Shellcode', 'Worms'], \"Attack\")\n",
    "# Chia tập dữ liệu thành X và y\n",
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "# Chia tap du lieu thanh 2 tap train: test=8:2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "'''Ap dung thuat toan'''\n",
    "# Sử dụng thuật toán Linear Regression để phát hiện các outlier trong tập dữ liệu\n",
    "reg = LinearRegression ()\n",
    "reg.fit(X_train, y_train)\n",
    "# Tính khoảng cách từ mỗi điểm đến mô hình\n",
    "distances = np.abs(reg. predict (X_test) - y_test)\n",
    "# Xác định ngưỡng khoảng cách để phân loại mẫu dữ liệu là outlier hay không\n",
    "threshold = np. percentile (distances, 95)\n",
    "labels = (np.abs(reg.predict(X_test) - y_test) > threshold).astype (int)\n",
    "\n",
    "'''Dua ra ket qua'''\n",
    "# Đánh giá mô hình\n",
    "y_pred= labels\n",
    "precision= precision_score(y_test, y_pred)\n",
    "accuracy= accuracy_score(y_test, y_pred)\n",
    "f1= f1_score(y_test, y_pred)\n",
    "recall= recall_score(y_test,y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:2f}\")\n",
    "print(f\"Accuracy: {accuracy:2f}\")\n",
    "print(f\"f1_score: {f1:2f}\")\n",
    "print(f\"Recall: {recall:2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "# Đọc dữ liệu từ file csv vào dataframe\n",
    "df = pd. read_csv(\"/content/drive/MyDrive/Exe1_dataset/UNSW-NB15_1_label.csv\")\n",
    "\n",
    "'''Tien xu ly du lieu'''\n",
    "# Thay thế giá trị NaN trong các cột numerical bằng mean của cột đó\n",
    "num_cols = df.select_dtypes (include=np. number).columns\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "# Chuyển đổi các giá trị categorical thành dạng số\n",
    "cat_cols = df.select_dtypes (include='object').columns\n",
    "for col in cat_cols:\n",
    "    df [col] = pd. Categorical(df[col])\n",
    "    df[col] = df[col].cat.codes\n",
    "\n",
    "# Chuẩn hóa MixMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "\n",
    "\n",
    "# Gom nhóm các dạng tấn công khác nhau vào cùng một nhãn \"Attack\"\n",
    "df['state'] = df['state'].replace(['Fuzzers', 'Reconnaissance', 'Exploits', 'Analysis', 'Backdoor', 'DoS', 'Shellcode', 'Worms'], \"Attack\")\n",
    "\n",
    "\n",
    "# Chia tập dữ liệu thành X và y\n",
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "# Chia tap du lieu thanh 2 tap train: test=8:2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "''' Ap dung thuật toan '''\n",
    "# Sử dụng thuật toán SVM để phát hiện các outlier trong tập dữ liệu\n",
    "clf = SVC (kernel='linear', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "#Dự đoán nhãn outlier cho toàn bộ tập dữ liệu\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "''' Dua ra ket qua '''\n",
    "# Đánh giá mô hình\n",
    "precision= precision_score(y_test, y_pred)\n",
    "accuracy= accuracy_score(y_test, y_pred)\n",
    "f1= f1_score(y_test, y_pred)\n",
    "recall= recall_score(y_test,y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:2f}\")\n",
    "print(f\"Accuracy: {accuracy:2f}\")\n",
    "print(f\"F1_score: {f1:2f}\")\n",
    "print(f\"Recall: {recall:2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
